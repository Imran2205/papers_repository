### [Vid2Seq: Large-Scale Pretraining of a Visual Language Model for Dense Video Captioning](https://arxiv.org/pdf/2302.14115.pdf)
```angular2html
@inproceedings{chi2022infogcn,
  title={Infogcn: Representation learning for human skeleton-based action recognition},
  author={Chi, Hyung-gun and Ha, Myoung Hoon and Chi, Seunggeun and Lee, Sang Wan and Huang, Qixing and Ramani, Karthik},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={20186--20196},
  year={2022}
}
```
---
### [ImageBind: One Embedding Space To Bind Them All](https://openaccess.thecvf.com/content/CVPR2023/papers/Girdhar_ImageBind_One_Embedding_Space_To_Bind_Them_All_CVPR_2023_paper.pdf)
```angular2html
@inproceedings{girdhar2023imagebind,
  title={Imagebind: One embedding space to bind them all},
  author={Girdhar, Rohit and El-Nouby, Alaaeldin and Liu, Zhuang and Singh, Mannat and Alwala, Kalyan Vasudev and Joulin, Armand and Misra, Ishan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15180--15190},
  year={2023}
}
```
---
### [MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge](https://arxiv.org/pdf/2206.08853)
```angular2html
@article{fan2022minedojo,
  title={Minedojo: Building open-ended embodied agents with internet-scale knowledge},
  author={Fan, Linxi and Wang, Guanzhi and Jiang, Yunfan and Mandlekar, Ajay and Yang, Yuncong and Zhu, Haoyi and Tang, Andrew and Huang, De-An and Zhu, Yuke and Anandkumar, Anima},
  journal={arXiv preprint arXiv:2206.08853},
  year={2022}
}
```
---
### [Decoupling Human and Camera Motion from Videos in the Wild](https://openaccess.thecvf.com/content/CVPR2023/papers/Ye_Decoupling_Human_and_Camera_Motion_From_Videos_in_the_Wild_CVPR_2023_paper.pdf)
```angular2html
@inproceedings{ye2023decoupling,
  title={Decoupling human and camera motion from videos in the wild},
  author={Ye, Vickie and Pavlakos, Georgios and Malik, Jitendra and Kanazawa, Angjoo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={21222--21232},
  year={2023}
}
```
---
### [Learning to Segment Rigid Motions from Two Frames](http://openaccess.thecvf.com/content/CVPR2021/papers/Yang_Learning_To_Segment_Rigid_Motions_From_Two_Frames_CVPR_2021_paper.pdf)
```angular2html
@inproceedings{yang2021learning,
  title={Learning to segment rigid motions from two frames},
  author={Yang, Gengshan and Ramanan, Deva},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1266--1275},
  year={2021}
}
```
---
### [BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models](https://arxiv.org/pdf/2301.12597)
```angular2html
@article{li2023blip,
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  journal={arXiv preprint arXiv:2301.12597},
  year={2023}
}
```
---
### [Toward Automatic Audio Description Generation for Accessible Videos](https://par.nsf.gov/servlets/purl/10223292)
```angular2html
@inproceedings{wang2021toward,
  title={Toward automatic audio description generation for accessible videos},
  author={Wang, Yujia and Liang, Wei and Huang, Haikun and Zhang, Yongqi and Li, Dingzeyu and Yu, Lap-Fai},
  booktitle={Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
  pages={1--12},
  year={2021}
}
```
---
### [Weakly Supervised Dense Event Captioning in Videos](https://proceedings.neurips.cc/paper/2018/file/49af6c4e558a7569d80eee2e035e2bd7-Paper.pdf)
```angular2html
@article{duan2018weakly,
  title={Weakly supervised dense event captioning in videos},
  author={Duan, Xuguang and Huang, Wenbing and Gan, Chuang and Wang, Jingdong and Zhu, Wenwu and Huang, Junzhou},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}
```
---
### [Playing for Data: Ground Truth from Computer Games](https://arxiv.org/pdf/1608.02192)
```angular2html
@inproceedings{richter2016playing,
  title={Playing for data: Ground truth from computer games},
  author={Richter, Stephan R and Vineet, Vibhav and Roth, Stefan and Koltun, Vladlen},
  booktitle={Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part II 14},
  pages={102--118},
  year={2016},
  organization={Springer}
}
```
---
### [Playing for benchmarks](http://openaccess.thecvf.com/content_ICCV_2017/papers/Richter_Playing_for_Benchmarks_ICCV_2017_paper.pdf)
```angular2html
@inproceedings{richter2017playing,
  title={Playing for benchmarks},
  author={Richter, Stephan R and Hayder, Zeeshan and Koltun, Vladlen},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={2213--2222},
  year={2017}
}
```
---
### [From Coarse to Fine: Robust Hierarchical Localization at Large Scale](http://openaccess.thecvf.com/content_CVPR_2019/papers/Sarlin_From_Coarse_to_Fine_Robust_Hierarchical_Localization_at_Large_Scale_CVPR_2019_paper.pdf)
```angular2html
@inproceedings{sarlin2019coarse,
  title={From coarse to fine: Robust hierarchical localization at large scale},
  author={Sarlin, Paul-Edouard and Cadena, Cesar and Siegwart, Roland and Dymczyk, Marcin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12716--12725},
  year={2019}
}
```
---
### [Self-Improving Semantic Perception for Indoor Localisation](https://proceedings.mlr.press/v164/blum22a/blum22a.pdf)
```angular2html
@inproceedings{blum2022self,
  title={Self-Improving semantic perception for Indoor localisation},
  author={Blum, Hermann and Milano, Francesco and Zurbr{\"u}gg, Ren{\'e} and Siegwart, Roland and Cadena, Cesar and Gawel, Abel},
  booktitle={Conference on Robot Learning},
  pages={1211--1222},
  year={2022},
  organization={PMLR}
}
```
---
### [ATOMIC: An Atlas of Machine Commonsense for If-Then Reasoning]()
```angular2html

```
---
### [InfoGCN: Representation Learning for Human Skeleton-based Action Recognition]()
```angular2html

```
---
### [What Makes Videos Accessible to Blind and Visually Impaired People?]()
```angular2html

```
---
### ["Person, Shoes, Tree. Is the Person Naked?" What People with Vision Impairment Want in Image Descriptions]()
```angular2html

```
---
### [Going Beyond One-Size-Fits-All Image Descriptions to Satisfy the Information Wants of People Who are Blind or Have Low Vision]()
```angular2html

```
---
### [Opportunities for Supporting Self-efficacy Through Orientation & Mobility Training Technologies for Blind and Partially Sighted People]()
```angular2html

```
---
### [GMPC-Tracker: Global Multi-object Tracking Using Generalized Minimum Clique Graphs]()
```angular2html

```
---
### [Toward Automatic Audio Description Generation for Accessible Videos]()
```angular2html

```
---
### [A Benchmark and Simulator for UAV Tracking]()
```angular2html

```
---
### [Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing]()
```angular2html

```
---
### [Mask2Former: Masked-attention Mask Transformer for Universal Image Segmentation]()
```angular2html

```
---
### [Qetch: Time Series Querying with Expressive Sketches]()
```angular2html

```
---
### [Masked-attention Mask Transformer for Universal Image Segmentation]()
```angular2html

```
---
### [Revealing the Dark Secrets of Masked Image Modeling]()
```angular2html

```
---
### [Attention Attention Everywhere: Monocular Depth Prediction with Skip Attention]()
```angular2html

```
---
### [Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth]()
```angular2html

```
---
### [Expanding Language-Image Pretrained Models for General Video Recognition]()
```angular2html

```
---
### [Expanding Language-Image Pretrained Models for General Video Recognition]()
```angular2html

```
---
### [RELLIS-3D: A Multi-modal Dataset for Off-Road Robotics]()
```angular2html

```
---
### [Learning to Segment Rigid Motions from Two Frames]()
```angular2html

```
---
### [CelebV-Text: A Large-Scale Facial Text-Video Dataset]()
```angular2html

```
---
### [OpenAI Gym]()
```angular2html

```
---
### [Relation-Aware Graph Convolutional Networks for Agent-Initiated Social E-Commerce Recommendation]()
```angular2html

```
---
### [Superpoint: Self-supervised interest point detection and description]()
```angular2html

```
---
### [A novel parametrization of the perspective-three-point problem for a direct computation of absolute camera position and orientation](https://www.researchgate.net/profile/Davide-Scaramuzza-3/publication/319770452_A_novel_parametrization_of_the_perspective-three-point_problem_for_a_direct_computation_of_absolute_camera_position_and_orientation/links/5a423ec2a6fdcce1971426ce/A-novel-parametrization-of-the-perspective-three-point-problem-for-a-direct-computation-of-absolute-camera-position-and-orientation.pdf)
```angular2html

```
---
### [Structure-from-motion revisited](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Schonberger_Structure-From-Motion_Revisited_CVPR_2016_paper.pdf)
```angular2html

```
---
### [The tenth visual object tracking vot2022 challenge results]()
```angular2html
@inproceedings{kristan2023tenth,
  title={The tenth visual object tracking vot2022 challenge results},
  author={Kristan, Matej and Leonardis, Ale{\v{s}} and Matas, Ji{\v{r}}{\'\i} and Felsberg, Michael and Pflugfelder, Roman and K{\"a}m{\"a}r{\"a}inen, Joni-Kristian and Chang, Hyung Jin and Danelljan, Martin and Zajc, Luka {\v{C}}ehovin and Luke{\v{z}}i{\v{c}}, Alan and others},
  booktitle={Computer Vision--ECCV 2022 Workshops: Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part VIII},
  pages={431--460},
  year={2023},
  organization={Springer}
}
```
---
### [Lasot: A high-quality benchmark for large-scale single object tracking]()
```angular2html
@inproceedings{fan2019lasot,
  title={Lasot: A high-quality benchmark for large-scale single object tracking},
  author={Fan, Heng and Lin, Liting and Yang, Fan and Chu, Peng and Deng, Ge and Yu, Sijia and Bai, Hexin and Xu, Yong and Liao, Chunyuan and Ling, Haibin},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={5374--5383},
  year={2019}
}
```
---
### [Probabilistic Volumetric Fusion for Dense Monocular SLAM]()
```angular2html
@inproceedings{rosinol2023probabilistic,
  title={Probabilistic Volumetric Fusion for Dense Monocular SLAM},
  author={Rosinol, Antoni and Leonard, John J and Carlone, Luca},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={3097--3105},
  year={2023}
}
```
### [SegMap: Segment-based mapping and localization using data-driven descriptors]()
```angular2html
@article{dube2020segmap,
  title={SegMap: Segment-based mapping and localization using data-driven descriptors},
  author={Dube, Renaud and Cramariuc, Andrei and Dugas, Daniel and Sommer, Hannes and Dymczyk, Marcin and Nieto, Juan and Siegwart, Roland and Cadena, Cesar},
  journal={The International Journal of Robotics Research},
  volume={39},
  number={2-3},
  pages={339--355},
  year={2020},
  publisher={Sage Publications Sage UK: London, England}
}
```
---
